{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305006a8",
   "metadata": {},
   "source": [
    "**Code to download power generation and power demand data from the TSO of Bosnia and Herzegovina (NOSBIH). Output saved in long format CSV. Skips the 29th of February making the time series easier to compare across years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Period of data ---\n",
    "start_date_str = \"01.01.2023\"\n",
    "# Set a specific end date\n",
    "end_date_str = \"04.01.2023\"\n",
    "# or download all data availabel to date\n",
    "#end_date_str = datetime.now().strftime(\"%d.%m.%Y\")  # Today's date\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, \"%d.%m.%Y\")\n",
    "end_date = datetime.strptime(end_date_str, \"%d.%m.%Y\")\n",
    "date_list = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Request setup\n",
    "url = \"https://www.nosbih.ba/en/wp-admin/admin-ajax.php\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "all_data = []\n",
    "# Fetch and parse data\n",
    "for date in tqdm(date_list, desc=\"Fetching data\"):\n",
    "    if date.month == 2 and date.day == 29:\n",
    "        print(f\"Skipping {date.strftime('%Y-%m-%d')} (Leap Year Day)\")\n",
    "        continue\n",
    "\n",
    "    date_str = date.strftime(\"%d.%m.%Y.\")\n",
    "    display_date = date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    form_data = {\n",
    "        \"action\": \"production\",\n",
    "        \"production\": f\"date={date_str}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, data=form_data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        html = response.json()['data']\n",
    "\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        rows = soup.select(\"table#productionTable tbody tr\")\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) >= 5:\n",
    "                time_val = cols[0].text.strip()\n",
    "\n",
    "                # Handle conversion with fallback to None\n",
    "                try:\n",
    "                    power_generation = float(cols[2].text.strip()) if cols[2].text.strip() else None\n",
    "                except ValueError:\n",
    "                    power_generation = None\n",
    "\n",
    "                try:\n",
    "                    electricity_demand = float(cols[4].text.strip()) if cols[4].text.strip() else None\n",
    "                except ValueError:\n",
    "                    electricity_demand = None\n",
    "\n",
    "                all_data.append({\n",
    "                    \"date\": display_date,\n",
    "                    \"time\": time_val,\n",
    "                    \"power_generation\": power_generation,\n",
    "                    \"electricity_demand\": electricity_demand\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {display_date}: {e}\")\n",
    "\n",
    "# Create DataFrame from scraped data\n",
    "df = pd.DataFrame(all_data)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"date\"] + \" \" + df[\"time\"], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Create full hourly time range (excluding Feb 29)\n",
    "full_range = pd.date_range(start=start_date, end=end_date + timedelta(days=1), freq='H', inclusive='left')\n",
    "full_range = full_range[~((full_range.month == 2) & (full_range.day == 29))]  # Remove leap day\n",
    "\n",
    "# Create empty DataFrame for full range\n",
    "full_df = pd.DataFrame({\"datetime\": full_range})\n",
    "full_df[\"date\"] = full_df[\"datetime\"].dt.strftime(\"%Y-%m-%d\")\n",
    "full_df[\"time\"] = full_df[\"datetime\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "# Merge full timeline with actual data\n",
    "merged_df = pd.merge(full_df, df.drop(columns=[\"date\", \"time\"]), on=\"datetime\", how=\"left\")\n",
    "\n",
    "# Reorder so 00:00 is at the end of each day\n",
    "def sort_day_correctly(group):\n",
    "    group = group.copy()\n",
    "    group['time_order'] = group['time'].apply(lambda t: \"24:00\" if t == \"00:00\" else t)\n",
    "    group = group.sort_values(by='time_order')\n",
    "    return group.drop(columns='time_order')\n",
    "\n",
    "df_sorted = merged_df.groupby(merged_df[\"datetime\"].dt.date, group_keys=False).apply(sort_day_correctly)\n",
    "\n",
    "# Replace NaNs with empty cells (None)\n",
    "df_sorted = df_sorted.where(pd.notnull(df_sorted), None)\n",
    "\n",
    "# Save CSV\n",
    "folder_path = os.path.join(\"data\", start_date.strftime(\"%Y\"), start_date.strftime(\"%m\"))\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "output_filename = f\"nosbih_{start_date_str.replace('.', '-')}_to_{end_date_str.replace('.', '-')}.csv\"\n",
    "output_path = os.path.join(folder_path, output_filename)\n",
    "df_sorted.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"CSV saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf336bd5",
   "metadata": {},
   "source": [
    "**The following code illustrates the visualization of the downloaded time series data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# --- Plotting each day with correct x-axis order ---\n",
    "unique_dates = df_sorted[\"date\"].unique()\n",
    "fig, axs = plt.subplots(len(unique_dates), 1, figsize=(8, 5 * len(unique_dates)), sharey=True)\n",
    "\n",
    "if len(unique_dates) == 1:\n",
    "    axs = [axs]  # force list if only one subplot\n",
    "\n",
    "for ax, date in zip(axs, unique_dates):\n",
    "    day_df = df_sorted[df_sorted[\"date\"] == date]\n",
    "    ax.plot(day_df[\"time\"], day_df[\"power_generation\"], label=\"Power Generation\", color=\"green\")\n",
    "    ax.plot(day_df[\"time\"], day_df[\"electricity_demand\"], label=\"Electricity Demand\", color=\"red\")\n",
    "    ax.set_title(f\"Electricity Data for {date}\")\n",
    "    ax.set_xlabel(\"Time of Day\")\n",
    "    ax.set_ylabel(\"MW\")\n",
    "    ax.set_xticks(day_df[\"time\"])\n",
    "    ax.set_xticklabels(day_df[\"time\"], rotation=45)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osembe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
