{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e17ebd",
   "metadata": {},
   "source": [
    "**Code to download hourly electricity demand data from the Albanian TSO (OST).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294ffb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threaded downloads and processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [01:46<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final output with all dates filled saved as long_format_demand_data_filled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/p8/lwc0sjsd4g3brnjz6n_q8chc0000gn/T/ipykernel_24074/1431091295.py:106: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_range = pd.date_range(start, end, freq='H')  # Removed closed='left'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "\n",
    "# Constants\n",
    "START_YEAR = 2025  # Only for 2025\n",
    "END_YEAR = 2025    # Only for 2025\n",
    "OUTPUT_DIR = \"Downloaded_Data\"\n",
    "BASE_URL = \"https://ost.al/wp-content/uploads\"\n",
    "MAX_WORKERS = 16  # Number of threads\n",
    "\n",
    "# Create output folder if not exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to process one date\n",
    "def process_date(args):\n",
    "    year, month, day = args\n",
    "    results = []\n",
    "\n",
    "    for upload_month in [month, month + 1]:\n",
    "        if upload_month > 12:\n",
    "            continue\n",
    "\n",
    "        date_str = f\"{day:02d}.{month:02d}.{year}\"\n",
    "        file_url = f\"{BASE_URL}/{year}/{upload_month:02d}/Publikimi-te-dhenave-{date_str}.xlsx\"\n",
    "        file_url_variation = f\"{BASE_URL}/{year}/{upload_month:02d}/Publikimi-te-dhenave-{date_str}-*.xlsx\"  # Variation for files with suffixes\n",
    "\n",
    "        try:\n",
    "            # Try the exact file first\n",
    "            response = requests.get(file_url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                # Process the file\n",
    "                wb = load_workbook(BytesIO(response.content), data_only=True)\n",
    "                sheet = wb['Publikime AL']\n",
    "                values = [sheet[f\"F{i}\"].value for i in range(160, 184)]\n",
    "\n",
    "                for hour, demand in enumerate(values, start=1):\n",
    "                    results.append({\n",
    "                        \"date\": f\"{year}-{month:02d}-{day:02d}\",\n",
    "                        \"hour\": hour,\n",
    "                        \"demand\": demand\n",
    "                    })\n",
    "                return results\n",
    "        except Exception:\n",
    "            # If the exact match fails, try the variation with any suffix\n",
    "            try:\n",
    "                response = requests.get(file_url_variation, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    # Process the file\n",
    "                    wb = load_workbook(BytesIO(response.content), data_only=True)\n",
    "                    sheet = wb['Publikime AL']\n",
    "                    values = [sheet[f\"F{i}\"].value for i in range(160, 184)]\n",
    "\n",
    "                    for hour, demand in enumerate(values, start=1):\n",
    "                        results.append({\n",
    "                            \"date\": f\"{year}-{month:02d}-{day:02d}\",\n",
    "                            \"hour\": hour,\n",
    "                            \"demand\": demand\n",
    "                        })\n",
    "                    return results\n",
    "            except Exception as e:\n",
    "                continue  # If no file is found, move to the next date\n",
    "\n",
    "    return []  # If nothing worked\n",
    "\n",
    "\n",
    "# Generate valid date combinations\n",
    "date_combos = []\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    for month in range(1, 13):\n",
    "        for day in range(1, 32):\n",
    "            try:\n",
    "                datetime(year, month, day)\n",
    "                date_combos.append((year, month, day))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting threaded downloads and processing...\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_date = {executor.submit(process_date, args): args for args in date_combos}\n",
    "        for future in tqdm(as_completed(future_to_date), total=len(future_to_date)):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                all_results.extend(result)\n",
    "\n",
    "    # Create a complete date-hour grid for all years (now only 24 hours per day)\n",
    "    full_index = []\n",
    "\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        start = datetime(year, 1, 1)\n",
    "        end = datetime(year + 1, 1, 1)\n",
    "        date_range = pd.date_range(start, end, freq='H')  # Removed closed='left'\n",
    "\n",
    "        for ts in date_range:\n",
    "            if ts.hour < 24:  # Ensure only 24 hours are used\n",
    "                full_index.append({\n",
    "                    \"date\": ts.strftime(\"%Y-%m-%d\"),\n",
    "                    \"hour\": ts.hour + 1  # Shift hours from 0-23 to 1-24\n",
    "                })\n",
    "\n",
    "    full_df = pd.DataFrame(full_index)\n",
    "\n",
    "    # Convert collected data into DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Merge the full grid with the actual data\n",
    "    merged_df = pd.merge(full_df, df, on=[\"date\", \"hour\"], how=\"left\")\n",
    "\n",
    "    # Optionally, fill missing demand with NaN or 0\n",
    "    merged_df['demand'] = merged_df['demand'].fillna(0)  # Use 0 or NaN depending on your preference\n",
    "\n",
    "    # Save to CSV\n",
    "    merged_df.to_csv(os.path.join(OUTPUT_DIR, \"long_format_demand_data_filled.csv\"), index=False)\n",
    "    print(\"✅ Final output with all dates filled saved as long_format_demand_data_filled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osembe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
